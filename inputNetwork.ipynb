{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes in a user-defined class with a certain name. Instantiating the network is simply for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArchitectureImporter:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.net_class = None\n",
    "\n",
    "    # Purpose: This method finds where the class of the Neural Network is defined\n",
    "    # Data: Reads the file path and class name from the config\n",
    "    def import_architecture(self):\n",
    "        # Get the file path and class name from the config\n",
    "        user_file = self.config.get(\"architecture_file\")\n",
    "        user_class_name = self.config.get(\"network_class_name\")\n",
    "\n",
    "        # Check if the provided file path is valid\n",
    "        if not os.path.isfile(user_file):\n",
    "            raise FileNotFoundError(f\"File '{user_file}' does not exist.\")\n",
    "\n",
    "        # Get the file name without extension\n",
    "        module_name = os.path.splitext(os.path.basename(user_file))[0]\n",
    "        spec = importlib.util.spec_from_file_location(module_name, user_file)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        if not hasattr(module, user_class_name):\n",
    "            raise AttributeError(f\"The file '{user_file}' does not have a class named '{user_class_name}'.\")\n",
    "\n",
    "        self.net_class = getattr(module, user_class_name)\n",
    "\n",
    "    # Purpose: Allows instantiation of the Network\n",
    "    # Returns: Class inputted by the user\n",
    "    def get_architecture(self):\n",
    "        return self.net_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This whole Block of code is all testing\n",
    "\n",
    "# # Load the configuration from the JSON file\n",
    "# config_file_path = os.getenv('CONFIG_FILE_PATH')\n",
    "# print(config_file_path)\n",
    "# with open(config_file_path, \"r\") as f:\n",
    "#     config = json.load(f)\n",
    "\n",
    "# importer = ArchitectureImporter(config)\n",
    "# importer.import_architecture()\n",
    "\n",
    "# nn_class = importer.get_architecture()\n",
    "\n",
    "# # Instantiating the network\n",
    "# nn1 = nn_class()\n",
    "# all_attributes = dir(nn1)\n",
    "# print(all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data\n",
    "#make constant in future\n",
    "csv_data = pd.read_csv('data/simpleReg.csv')\n",
    "\n",
    "a = csv_data['a'].values.reshape(-1, 1)\n",
    "b = csv_data['b'].values.reshape(-1, 1)\n",
    "y = csv_data['y'].values.reshape(-1, 1)\n",
    "\n",
    "# Convert to Tensors\n",
    "a_tensor = torch.tensor(a, dtype=torch.float32)\n",
    "b_tensor = torch.tensor(b, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "X_tensor = torch.cat((a_tensor, b_tensor), dim=1)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# #instantiate\n",
    "# simple_reg_nn1 = simple_reg_nn1_arch()\n",
    "# print(dir(simple_reg_nn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simoncole/seniorDesign/Large-Scale-Design-and-Analysis-of-Neural-Networks/config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration from the JSON file\n",
    "config_file_path = os.getenv('CONFIG_FILE_PATH')\n",
    "print(config_file_path)\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Get the architecture\n",
    "importer = ArchitectureImporter(config)\n",
    "importer.import_architecture()\n",
    "architecture = importer.get_architecture()\n",
    "\n",
    "num_networks = config.get(\"num_networks\")\n",
    "\n",
    "instantiated_networks = []\n",
    "for i in range(num_networks):\n",
    "    instantiated_networks.append(architecture())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(X_train, y_train, X_test, y_test, network, num_epochs):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr = 0.01)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward Pass\n",
    "        outputs = network(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print the loss every 100 epochs\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            # Evaluate on validation set\n",
    "            network.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = network(X_test)\n",
    "                test_loss = criterion(test_outputs, y_test)\n",
    "            network.train()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cy/1ymz7q691kxczsvbmngmymg40000gn/T/ipykernel_52945/1544460034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstantiated_networks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cy/1ymz7q691kxczsvbmngmymg40000gn/T/ipykernel_52945/4049064863.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(X_train, y_train, X_test, y_test, network, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#train\n",
    "num_epochs = config.get(\"num_epochs\")\n",
    "\n",
    "\n",
    "for network in instantiated_networks:\n",
    "    train_network(X_train, y_train, X_test, y_test, network, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
