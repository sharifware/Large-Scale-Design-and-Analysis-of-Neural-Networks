{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file takes in a user-defined class with a certain name. Instantiating the network is simply for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Get the file where the user defined the architecture of the Neural Network\n",
    "# and import the class of the Neural Network\n",
    "class ArchitectureImporter:\n",
    "\n",
    "    # Purpose: This method finds where the class of the Neural Network is defined\n",
    "    # Data: Doesnt require any inputs, but requests a file from the user (which need to be in the same directory as this one, for now)\n",
    "    # And requests the name of the class to be imported\n",
    "    # Returns: Nothing, but  saves both inputs from user\n",
    "    def import_architecture(self):\n",
    "        # Request the file path and class name from the user\n",
    "        user_file = input(\"Input the full path to the file: \")\n",
    "        user_class_name = input(\"Input the name of the NeuralNetwork's class: \")\n",
    "\n",
    "        # Check if the provided file path is valid\n",
    "        if not os.path.isfile(user_file):\n",
    "            raise FileNotFoundError(f\"File '{user_file}' does not exist.\")\n",
    "\n",
    "        # Get the file name without extension\n",
    "        # Crazy code sorry dw abt it\n",
    "        module_name = os.path.splitext(os.path.basename(user_file))[0]  \n",
    "        spec = importlib.util.spec_from_file_location(module_name, user_file)\n",
    "        module = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(module)\n",
    "\n",
    "        # Check if the module is valid\n",
    "        # Probably Need to make user re-input the value, we'll change that later\n",
    "        if not hasattr(module, user_class_name):\n",
    "            raise AttributeError(f\"The file '{user_file}' does not have a class named '{user_class_name}'.\")\n",
    "        \n",
    "        self.net_class = getattr(module, user_class_name)\n",
    "\n",
    "    # Purpose: Allows instantiation of the Network\n",
    "    # Returns: Class inputted by the user\n",
    "    def get_architecture(self):\n",
    "        return self.net_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'fc1', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "# This whole Block of code is all testing\n",
    "\n",
    "importer = ArchitectureImporter()\n",
    "importer.import_architecture()\n",
    "\n",
    "nn_class = importer.get_architecture()\n",
    "\n",
    "# Instantiating the network\n",
    "nn1 = nn_class()\n",
    "all_attributes = dir(nn1)\n",
    "print(all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 instances created.\n",
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n",
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Optionally, we can give the instances name\n",
    "\n",
    "k = input(\"How many Networks do you wish to Instantiate: \")\n",
    "k = int(k)\n",
    "\n",
    "instances = []\n",
    "\n",
    "for i in range(k):\n",
    "    instances.append(nn_class())\n",
    "\n",
    "print(f\"{len(instances)} instances created.\")\n",
    "\n",
    "# testing\n",
    "for instance in range(len(instances)):\n",
    "    print(instances[instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkAnalyzer:\n",
    "\n",
    "    def __init__(self, model_architecture: nn.Module, amount_to_produce: int, success_criteria: callable = None, max_attempts: float = None):\n",
    "        \"\"\"\n",
    "        This is the constructor to out network analyzer\n",
    "\n",
    "        Parameters: \n",
    "            model (nn.Module): PyTorch class specifying the Neural Network Architecture.\n",
    "            amount_to_produce (int): How many good Neural Networks to produce.\n",
    "            success_criteria (callable): Lambda expression that sets a user-defined criteria for the loss.\\\n",
    "                The default is 10% loss.\n",
    "            max_attempts: Maximum amount of times a network should be instantiated in case an instance\\\n",
    "                does not meet the success criteria\n",
    "        \"\"\"\n",
    "        self.model_architecture = model_architecture\n",
    "        self.amount_to_produce = amount_to_produce\n",
    "        self.success_criteria = success_criteria if success_criteria is not None else self.default_success_criteria()\n",
    "        self.max_attempts = max_attempts if max_attempts is not None else self.default_max_attempts()\n",
    "    \n",
    "    def default_success_criteria(self):\n",
    "        \"\"\"\n",
    "        Makes the success criteria be a 10% loss if not specified by the user\n",
    "\n",
    "        Returns:    \n",
    "            Predefined 10% test-loss as success criteria\n",
    "        \"\"\"\n",
    "        return 10\n",
    "    \n",
    "    def default_max_attempts(self):\n",
    "        \"\"\"\n",
    "        Makes it so that the maximum attempts is an extra 30% over the number of networks to produce,\\\n",
    "        if not specified by the user\n",
    "\n",
    "        Returns:\n",
    "            The number of max attempts\n",
    "        \"\"\"\n",
    "        return int(self.amount_to_produce * 1.3)\n",
    "    \n",
    "    def show_loss(epoch, loss_value):\n",
    "        \"\"\"\n",
    "        This function prints the loss, and is used by the training function.\n",
    "        This is its own function so it can be used by the user if they \n",
    "        wish to define their own training function.\n",
    "        \"\"\"\n",
    "        print(f\"Epoch [{epoch+1}], Loss: {loss_value:.4f}\")\n",
    "    \n",
    "    def train_network(self, X_train, y_train, X_test, y_test, network: nn.Module, num_epochs, optimizer: torch.optim.SGD):\n",
    "        \"\"\"\n",
    "        Function that trains the network\n",
    "\n",
    "        Parameters:\n",
    "            X_train: Data to train the model\n",
    "            Y_train: Labels of the training data\n",
    "            X_test: Data to test the model\n",
    "            Y_test: Labels of the testing data\n",
    "        \"\"\"\n",
    "    \n",
    "        criterion = nn.MSELoss() # Don't like\n",
    "        optimizer = torch.optim.SGD(network.parameters(), lr = 0.01)\n",
    "        for epoch in range(num_epochs):\n",
    "            network.train()\n",
    "            # Forward Pass\n",
    "            outputs = network(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "\n",
    "            # Backprop and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        self.show_loss(epoch, loss.item())\n",
    "\n",
    "    \n",
    "    \n",
    "    def generate_networks(self):\n",
    "\n",
    "        self.models = []\n",
    "\n",
    "        for i in range(self.amount_to_produce):\n",
    "            self.models.append()\n",
    "\n",
    "        print(f\"{len(instances)} instances created.\")\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network2(self, model: nn.Module, train_loader: DataLoader, test_loader: DataLoader, num_epochs: int, optimizer: torch.optim.SGD, loss_fn: torch.nn):\n",
    "        \"\"\"\n",
    "        Function that trains the network\n",
    "\n",
    "        Parameters:\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                input, target = batch\n",
    "                output = model(input)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(self, model: nn.Module, train_loader: DataLoader, loss_fn: torch.nn, optimizer: torch.optim.SGD, num_epochs: int):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print loss after every epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        self.print_loss(epoch, epoch_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
